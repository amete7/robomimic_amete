
============= Initialized Observation Utils with Obs Spec =============

using obs modality: low_dim with keys: ['robot0_gripper_qpos', 'object', 'robot0_eef_quat', 'robot0_eef_pos']
using obs modality: rgb with keys: []
using obs modality: depth with keys: []
using obs modality: scan with keys: []

============= Loaded Environment Metadata =============
obs key object with shape (14,)
obs key robot0_eef_pos with shape (3,)
obs key robot0_eef_quat with shape (4,)
obs key robot0_gripper_qpos with shape (2,)

/home/amete7/miniconda3/envs/robomimic/lib/python3.8/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")

============= Model Summary =============
Skill_VAE (
  ModuleDict(
    (vae): SkillVAE(
      (vq): FSQ(
        (project_in): Linear(in_features=256, out_features=4, bias=True)
        (project_out): Linear(in_features=4, out_features=256, bias=True)
      )
      (action_proj): Linear(in_features=7, out_features=256, bias=True)
      (action_head): Linear(in_features=256, out_features=7, bias=True)
      (conv_block): ResidualTemporalBlock(
        (blocks): ModuleList(
          (0): Conv1dBlock(
            (block): Sequential(
              (0): CausalConv1d(
                (conv): Conv1d(256, 256, kernel_size=(5,), stride=(2,), padding=(4,))
              )
              (1): Rearrange('batch channels horizon -> batch channels 1 horizon')
              (2): GroupNorm(8, 256, eps=1e-05, affine=True)
              (3): Rearrange('batch channels 1 horizon -> batch channels horizon')
              (4): Mish()
            )
          )
          (1): Conv1dBlock(
            (block): Sequential(
              (0): CausalConv1d(
                (conv): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(2,))
              )
              (1): Rearrange('batch channels horizon -> batch channels 1 horizon')
              (2): GroupNorm(8, 256, eps=1e-05, affine=True)
              (3): Rearrange('batch channels 1 horizon -> batch channels horizon')
              (4): Mish()
            )
          )
          (2): Conv1dBlock(
            (block): Sequential(
              (0): CausalConv1d(
                (conv): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(2,))
              )
              (1): Rearrange('batch channels horizon -> batch channels 1 horizon')
              (2): GroupNorm(8, 256, eps=1e-05, affine=True)
              (3): Rearrange('batch channels 1 horizon -> batch channels horizon')
              (4): Mish()
            )
          )
        )
      )
      (encoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (decoder): TransformerDecoder(
        (layers): ModuleList(
          (0-3): 4 x TransformerDecoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (multihead_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
            )
            (linear1): Linear(in_features=256, out_features=1024, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=1024, out_features=256, bias=True)
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
            (dropout3): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (add_positional_emb): Summer(
        (penc): PositionalEncoding1D()
      )
      (fixed_positional_emb): PositionalEncoding1D()
    )
  )
)

SequenceDataset: loading dataset into memory...
  0%|          | 0/300 [00:00<?, ?it/s] 24%|##3       | 71/300 [00:00<00:00, 702.76it/s] 47%|####7     | 142/300 [00:00<00:00, 705.30it/s] 71%|#######1  | 213/300 [00:00<00:00, 697.60it/s] 94%|#########4| 283/300 [00:00<00:00, 668.79it/s]100%|##########| 300/300 [00:00<00:00, 672.21it/s]
SequenceDataset: caching get_item calls...
  0%|          | 0/62756 [00:00<?, ?it/s]  2%|1         | 1017/62756 [00:00<00:06, 10156.64it/s]  3%|3         | 2094/62756 [00:00<00:05, 10514.23it/s]  5%|5         | 3253/62756 [00:00<00:05, 11002.00it/s]  7%|7         | 4425/62756 [00:00<00:05, 11284.54it/s]  9%|8         | 5565/62756 [00:00<00:05, 11324.29it/s] 11%|#         | 6698/62756 [00:00<00:05, 11182.64it/s] 13%|#2        | 8021/62756 [00:00<00:04, 11845.53it/s] 15%|#4        | 9207/62756 [00:00<00:04, 11834.82it/s] 17%|#6        | 10392/62756 [00:00<00:04, 11234.02it/s] 19%|#8        | 11686/62756 [00:01<00:04, 11739.03it/s] 21%|##        | 13159/62756 [00:01<00:03, 12627.44it/s] 23%|##2       | 14429/62756 [00:01<00:05, 9341.92it/s]  25%|##4       | 15553/62756 [00:01<00:04, 9793.12it/s] 27%|##6       | 16632/62756 [00:01<00:04, 10012.64it/s] 28%|##8       | 17819/62756 [00:01<00:04, 10504.66it/s] 31%|###       | 19205/62756 [00:01<00:03, 11426.16it/s] 33%|###2      | 20602/62756 [00:01<00:03, 12142.77it/s] 35%|###4      | 21918/62756 [00:01<00:03, 12432.46it/s] 37%|###7      | 23306/62756 [00:02<00:03, 12850.84it/s] 39%|###9      | 24649/62756 [00:02<00:02, 13020.08it/s] 41%|####1     | 25967/62756 [00:02<00:02, 12896.58it/s] 43%|####3     | 27268/62756 [00:02<00:02, 12656.93it/s] 45%|####5     | 28542/62756 [00:02<00:03, 11269.24it/s] 47%|####7     | 29702/62756 [00:02<00:02, 11181.66it/s] 49%|####9     | 31054/62756 [00:02<00:02, 11824.65it/s] 51%|#####1    | 32258/62756 [00:02<00:02, 11245.32it/s] 53%|#####3    | 33509/62756 [00:02<00:02, 11590.15it/s] 55%|#####5    | 34684/62756 [00:03<00:02, 11531.31it/s] 57%|#####7    | 35849/62756 [00:03<00:02, 11217.47it/s] 59%|#####8    | 36992/62756 [00:03<00:02, 11274.69it/s] 61%|######    | 38246/62756 [00:03<00:02, 11638.56it/s] 63%|######3   | 39697/62756 [00:03<00:01, 12474.42it/s] 66%|######5   | 41234/62756 [00:03<00:01, 13324.13it/s] 68%|######7   | 42661/62756 [00:03<00:01, 13601.60it/s] 70%|#######   | 44034/62756 [00:03<00:01, 13636.81it/s] 72%|#######2  | 45401/62756 [00:03<00:01, 13194.71it/s] 74%|#######4  | 46726/62756 [00:04<00:01, 11169.02it/s] 77%|#######6  | 48163/62756 [00:04<00:01, 12001.96it/s] 79%|#######9  | 49661/62756 [00:04<00:01, 12807.86it/s] 82%|########1 | 51215/62756 [00:04<00:00, 13568.27it/s] 84%|########4 | 52716/62756 [00:04<00:00, 13978.94it/s] 86%|########6 | 54142/62756 [00:04<00:00, 12988.74it/s] 89%|########8 | 55568/62756 [00:04<00:00, 13338.93it/s] 91%|######### | 56984/62756 [00:04<00:00, 13570.21it/s] 93%|#########3| 58478/62756 [00:04<00:00, 13962.56it/s] 96%|#########5| 60018/62756 [00:04<00:00, 14379.70it/s] 98%|#########8| 61515/62756 [00:05<00:00, 14548.77it/s]100%|##########| 62756/62756 [00:05<00:00, 12233.33it/s]

============= Training Dataset =============
SequenceDataset (
	path=datasets/can/mh/low_dim_v141.hdf5
	obs_keys=('object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos')
	seq_length=32
	filter_key=none
	frame_stack=1
	pad_seq_length=True
	pad_frame_stack=True
	goal_mode=none
	cache_mode=all
	num_demos=300
	num_sequences=62756
)

**************************************************
Warnings generated by robomimic have been duplicated here (from above) for convenience. Please check them carefully.
**************************************************

  0%|          | 0/245 [00:00<?, ?it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  0%|          | 1/245 [00:04<16:35,  4.08s/it]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  1%|          | 2/245 [00:04<07:05,  1.75s/it]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  2%|1         | 4/245 [00:04<02:50,  1.42it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  2%|2         | 6/245 [00:04<01:38,  2.44it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  3%|3         | 8/245 [00:04<01:06,  3.58it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  4%|4         | 10/245 [00:04<00:50,  4.68it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  5%|4         | 12/245 [00:05<00:39,  5.97it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  6%|5         | 14/245 [00:05<00:32,  7.16it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  7%|6         | 16/245 [00:05<00:27,  8.20it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  7%|7         | 18/245 [00:05<00:24,  9.12it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  8%|8         | 20/245 [00:05<00:22, 10.02it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
  9%|8         | 22/245 [00:05<00:20, 10.73it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 10%|9         | 24/245 [00:06<00:19, 11.37it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 11%|#         | 26/245 [00:06<00:18, 11.67it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 11%|#1        | 28/245 [00:06<00:18, 11.80it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 12%|#2        | 30/245 [00:06<00:18, 11.91it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 13%|#3        | 32/245 [00:06<00:18, 11.48it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 14%|#3        | 34/245 [00:06<00:19, 11.08it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 15%|#4        | 36/245 [00:07<00:18, 11.21it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 16%|#5        | 38/245 [00:07<00:18, 11.34it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 16%|#6        | 40/245 [00:07<00:18, 11.21it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 17%|#7        | 42/245 [00:07<00:18, 10.93it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 18%|#7        | 44/245 [00:07<00:18, 10.75it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 19%|#8        | 46/245 [00:07<00:18, 11.04it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 20%|#9        | 48/245 [00:08<00:17, 11.48it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 20%|##        | 50/245 [00:08<00:16, 11.85it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 21%|##1       | 52/245 [00:08<00:16, 11.71it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 22%|##2       | 54/245 [00:08<00:15, 12.06it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 23%|##2       | 56/245 [00:08<00:15, 12.28it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 24%|##3       | 58/245 [00:08<00:15, 12.43it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 24%|##4       | 60/245 [00:09<00:14, 12.43it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 25%|##5       | 62/245 [00:09<00:14, 12.34it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 26%|##6       | 64/245 [00:09<00:14, 12.49it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 27%|##6       | 66/245 [00:09<00:14, 12.63it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 28%|##7       | 68/245 [00:09<00:14, 12.50it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 29%|##8       | 70/245 [00:09<00:14, 12.44it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 29%|##9       | 72/245 [00:10<00:13, 12.54it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 30%|###       | 74/245 [00:10<00:13, 12.57it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 31%|###1      | 76/245 [00:10<00:13, 12.32it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 32%|###1      | 78/245 [00:10<00:13, 11.93it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 33%|###2      | 80/245 [00:10<00:13, 12.03it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 33%|###3      | 82/245 [00:10<00:13, 12.13it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 34%|###4      | 84/245 [00:11<00:13, 11.77it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 35%|###5      | 86/245 [00:11<00:14, 10.67it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 36%|###5      | 88/245 [00:11<00:13, 11.35it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 37%|###6      | 90/245 [00:11<00:13, 11.79it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 38%|###7      | 92/245 [00:11<00:12, 12.10it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 38%|###8      | 94/245 [00:11<00:12, 12.30it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 39%|###9      | 96/245 [00:12<00:11, 12.54it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 40%|####      | 98/245 [00:12<00:11, 12.56it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 41%|####      | 100/245 [00:12<00:11, 12.77it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 42%|####1     | 102/245 [00:12<00:11, 12.46it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 42%|####2     | 104/245 [00:12<00:11, 12.41it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 43%|####3     | 106/245 [00:12<00:11, 12.60it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 44%|####4     | 108/245 [00:13<00:11, 12.43it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 45%|####4     | 110/245 [00:13<00:10, 12.36it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 46%|####5     | 112/245 [00:13<00:10, 12.34it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 47%|####6     | 114/245 [00:13<00:10, 12.36it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 47%|####7     | 116/245 [00:13<00:11, 11.57it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 48%|####8     | 118/245 [00:13<00:10, 11.73it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 49%|####8     | 120/245 [00:14<00:10, 12.07it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 50%|####9     | 122/245 [00:14<00:10, 11.98it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 51%|#####     | 124/245 [00:14<00:10, 12.05it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 51%|#####1    | 126/245 [00:14<00:09, 12.06it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 52%|#####2    | 128/245 [00:14<00:09, 11.99it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 53%|#####3    | 130/245 [00:14<00:09, 11.60it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 54%|#####3    | 132/245 [00:15<00:09, 11.68it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 55%|#####4    | 134/245 [00:15<00:09, 11.95it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 56%|#####5    | 136/245 [00:15<00:09, 11.85it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 56%|#####6    | 138/245 [00:15<00:09, 11.78it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 57%|#####7    | 140/245 [00:15<00:08, 12.01it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 58%|#####7    | 142/245 [00:15<00:08, 11.85it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 59%|#####8    | 144/245 [00:16<00:08, 11.56it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 60%|#####9    | 146/245 [00:16<00:08, 11.67it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 60%|######    | 148/245 [00:16<00:08, 11.75it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 61%|######1   | 150/245 [00:16<00:08, 11.86it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 62%|######2   | 152/245 [00:16<00:07, 11.93it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 63%|######2   | 154/245 [00:16<00:07, 11.55it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 64%|######3   | 156/245 [00:17<00:07, 11.61it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 64%|######4   | 158/245 [00:17<00:07, 11.43it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 65%|######5   | 160/245 [00:17<00:07, 11.50it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 66%|######6   | 162/245 [00:17<00:07, 11.09it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 67%|######6   | 164/245 [00:17<00:07, 11.50it/s]dict_keys(['actions']) input keys
torch.Size([256, 32, 7]) action shape
 67%|######6   | 164/245 [00:17<00:08,  9.21it/s]
Traceback (most recent call last):
  File "robomimic/scripts/train.py", line 427, in <module>
    main(args)
  File "robomimic/scripts/train.py", line 378, in main
    train(config, device=device)
  File "robomimic/scripts/train.py", line 196, in train
    step_log = TrainUtils.run_epoch(
  File "/satassdscratch/amete7/robomimic_amete/robomimic/utils/train_utils.py", line 559, in run_epoch
    info = model.train_on_batch(input_batch, epoch, validate=validate)
  File "/satassdscratch/amete7/robomimic_amete/robomimic/algo/skill_vae.py", line 144, in train_on_batch
    recon_loss = self.loss(pred,batch["actions"])
  File "/home/amete7/miniconda3/envs/robomimic/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/amete7/miniconda3/envs/robomimic/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/satassdscratch/amete7/robomimic_amete/robomimic/models/skill_nets.py", line 298, in forward
    codes, _, pp, pp_sample, commitment_loss = self.quantize(z)
  File "/satassdscratch/amete7/robomimic_amete/robomimic/models/skill_nets.py", line 281, in quantize
    commitment_loss = torch.tensor([0.0]).to(z.device)
KeyboardInterrupt
